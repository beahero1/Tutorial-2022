{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d281121",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8266ec7",
   "metadata": {},
   "source": [
    "## Sign-up & Authentification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b654d44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = api_key\n",
    "api_key_secret = api_key_secret\n",
    "\n",
    "access_token = access_token\n",
    "access_token_secret = access_token_secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a99f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(api_key, api_key_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bacdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeaf2ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc735a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "api.update_status('Twitter API trial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa1607f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "api.destroy_status(id = 1502097617140203520)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8038e394",
   "metadata": {},
   "source": [
    "## Json\n",
    "\n",
    "Official doc: https://www.json.org/json-en.html\n",
    "\n",
    "- A data format designed for data exchange between systems and languages\n",
    "\n",
    "- Essentially a tree-like structure built on two types of structure common in most programming languages (akin to dictionary and list in Python)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bdf552",
   "metadata": {},
   "source": [
    "## Put tweets into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61139934",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_timeline = api.home_timeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1080baee",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce9e192",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_5 = my_timeline[4]\n",
    "tweet_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24f1299",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_5.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825b3291",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_5.user.screen_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88d4258",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars(tweet_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d54289b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars(tweet_5)['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bd99b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars(tweet_5)['user'].screen_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1014fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = set()\n",
    "# Python lists allow duplicate elements; sets do not.\n",
    "tweets_data = []\n",
    "\n",
    "for tweet in my_timeline:\n",
    "    tweet_dict = vars(tweet)\n",
    "    keys = tweet_dict.keys()\n",
    "    single_tweet_data = {\"user\": tweet.user.screen_name}\n",
    "    for k in keys:\n",
    "        v_type = type(tweet_dict[k])\n",
    "        if v_type in [str, int]:\n",
    "            single_tweet_data[k] = tweet_dict[k]\n",
    "            headers.add(k)\n",
    "    tweets_data.append(single_tweet_data)\n",
    "    \n",
    "columns = list(headers)\n",
    "columns.append(\"user\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19af55c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f55050",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweets_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f618a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(tweets_data, columns=columns)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01933a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_timeline_df(timeline):\n",
    "    headers = set()\n",
    "    tweets_data = []\n",
    "\n",
    "    for tweet in timeline:\n",
    "        tweet_dict = vars(tweet)\n",
    "        keys = tweet_dict.keys()\n",
    "        single_tweet_data = {\"user\": tweet.user.screen_name}\n",
    "        for k in keys:\n",
    "            v_type = type(tweet_dict[k])\n",
    "            if v_type in [str, int]:\n",
    "                single_tweet_data[k] = tweet_dict[k]\n",
    "                headers.add(k)\n",
    "        tweets_data.append(single_tweet_data)\n",
    "\n",
    "    columns = list(headers)\n",
    "    columns.append(\"user\")\n",
    "    \n",
    "    df = pd.DataFrame(tweets_data, columns = columns)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17963e6",
   "metadata": {},
   "source": [
    "## Tweets from other users and hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5865c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the latest tweets of the author of our textbook â€” Matthew Salganik\n",
    "\n",
    "user = 'msalganik'\n",
    "user_timeline = api.user_timeline(screen_name = user, count = 10)\n",
    "\n",
    "df_2 = extract_timeline_df(user_timeline)\n",
    "df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa69016",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2['text'][6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c6301f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "user_timeline = api.user_timeline(screen_name = user, count = 300)\n",
    "\n",
    "df_3 = extract_timeline_df(user_timeline)\n",
    "df_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39949455",
   "metadata": {},
   "source": [
    "There's a maximum number of tweets `user_timeline` can extract. To extract more tweets, we use `Cursor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0af945",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_timeline = tweepy.Cursor(api.user_timeline, screen_name = user).items(300)\n",
    "df_3 = extract_timeline_df(user_timeline)\n",
    "df_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c06d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search tweets by a keyword\n",
    "\n",
    "keywords = ['China', '#EconTwitter']\n",
    "search_timeline = tweepy.Cursor(api.search_tweets, q = keywords).items(10)\n",
    "\n",
    "df_4 = extract_timeline_df(search_timeline)\n",
    "df_4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3171ea40",
   "metadata": {},
   "source": [
    "## Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ce5222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a subclass of tweepy.Stream\n",
    "\n",
    "class Linstener(tweepy.Stream):\n",
    "\n",
    "    tweets = []\n",
    "    limit = 30\n",
    "    \n",
    "\n",
    "    def on_status(self, status):\n",
    "        self.tweets.append(status)\n",
    "        \n",
    "        # print(status.user.screen_name + \": \" + status.text)\n",
    "        \n",
    "        # stop streaming after 30 tweets\n",
    "        if len(self.tweets) == self.limit:\n",
    "            self.disconnect()\n",
    "\n",
    "# Notice Stream is a different application from API, we need to authenticate again. \n",
    "stream_tweet = Linstener(api_key, api_key_secret, access_token, access_token_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562d70e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stream by keywords\n",
    "\n",
    "keywords = ['Ukraine']\n",
    "\n",
    "stream_tweet.filter(track=keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e95db9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put streaming tweets into df\n",
    "\n",
    "columns = ['User', 'Tweet']\n",
    "data = []\n",
    "\n",
    "for tweet in stream_tweet.tweets:\n",
    "    data.append([tweet.user.screen_name, tweet.text])\n",
    "\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cd34bd",
   "metadata": {},
   "source": [
    "For more on Twitter Streaming, see https://developer.twitter.com/en/docs/tutorials/consuming-streaming-data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
